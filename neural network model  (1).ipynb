{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Keras specific\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lead the datasets\n",
    "df1 = pd.read_csv('Prop_cycle_250C - Feuille 1.csv')\n",
    "df2 = pd.read_csv('Prop_cycle_300C - Feuille 1.csv')\n",
    "df3 = pd.read_csv('Meth_cycle_300C - Feuille 1.csv')\n",
    "df4 = pd.read_csv('Prop_cycle_350C - Feuille 1.csv')\n",
    "df5 = pd.read_csv('Meth_cycle_350C - Feuille 1.csv')\n",
    "df6 = pd.read_csv('Tol_cycle_250C - Feuille 1.csv')\n",
    "df7 = pd.read_csv('Prop_cycle_200C - Feuille 1.csv')\n",
    "df8 = pd.read_csv('Formal_cycle_200C - Feuille 1.csv')\n",
    "df9 = pd.read_csv('Formal_cycle_250C - Feuille 1.csv')\n",
    "df10 = pd.read_csv('Formal_cycle_300C - Feuille 1.csv')\n",
    "df11 = pd.read_csv('Meth_cycle_250C - Feuille 1.csv')\n",
    "df12 = pd.read_csv('Formal_cycle_350C - Feuille 1.csv')\n",
    "df13 = pd.read_csv('Meth_cycle_200C - Feuille 1.csv')\n",
    "df14 = pd.read_csv('Tol_cycle_200C - Feuille 1.csv')\n",
    "df15 = pd.read_csv('Tol_cycle_300C - Feuille 1.csv')\n",
    "df16 = pd.read_csv('Tol_cycle_350C - Feuille 1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove missing values\n",
    "df1 = df1.dropna()\n",
    "df2 = df2.dropna()\n",
    "df3 = df3.dropna()\n",
    "df4 = df4.dropna()\n",
    "df5 = df5.dropna()\n",
    "df6 = df6.dropna()\n",
    "df7 = df7.dropna()\n",
    "df8 = df8.dropna()\n",
    "df9 = df9.dropna()\n",
    "df10 = df10.dropna()\n",
    "df11 = df11.dropna()\n",
    "df12 = df12.dropna()\n",
    "df13 = df13.dropna()\n",
    "df14 = df14.dropna()\n",
    "df15= df15.dropna()\n",
    "df16 = df16.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1= df1.merge(df2, on='Time(s)', how='left')\n",
    "d1 = d1.rename({'Response_x': '250C', 'Response_y': '300C'}, axis=1)\n",
    "d2=d1.merge(df4, on='Time(s)', how='left')\n",
    "data1=d2.merge(df7, on='Time(s)', how='left')\n",
    "data1 = data1.rename({'Response_x': '350C', 'Response_y': '200C'}, axis=1)\n",
    "data1= data1.dropna()\n",
    "l1=[]\n",
    "for i in range(len(data1)):\n",
    "    l1.append('Prop_cycle')\n",
    "data1['class']=l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1= df11.merge(df3, on='Time(s)', how='left')\n",
    "f1 = f1.rename({'Response_x': '250C', 'Response_y': '300C'}, axis=1)\n",
    "f2=f1.merge(df5, on='Time(s)', how='left')\n",
    "data2=f2.merge(df13, on='Time(s)', how='left')\n",
    "data2 = data2.rename({'Response_x': '350C', 'Response_y': '200C'}, axis=1)\n",
    "data2= data2.dropna()\n",
    "l2=[]\n",
    "for i in range(len(data2)):\n",
    "    l2.append('Meth_cycle')\n",
    "data2['class']=l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1= df6.merge(df15, on='Time(s)', how='left')\n",
    "w1 = w1.rename({'Response_x': '250C', 'Response_y': '300C'}, axis=1)\n",
    "w2=w1.merge(df16, on='Time(s)', how='left')\n",
    "data3=w2.merge(df14, on='Time(s)', how='left')\n",
    "data3 = data3.rename({'Response_x': '350C', 'Response_y': '200C'}, axis=1)\n",
    "data3= data3.dropna()\n",
    "l3=[]\n",
    "for i in range(len(data3)):\n",
    "    l3.append('Tol_cycle')\n",
    "data3['class']=l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1= df9.merge(df10, on='Time(s)', how='left')\n",
    "z1 = z1.rename({'Response_x': '250C', 'Response_y': '300C'}, axis=1)\n",
    "z2=z1.merge(df12, on='Time(s)', how='left')\n",
    "data4=z2.merge(df8, on='Time(s)', how='left')\n",
    "data4 = data4.rename({'Response_x': '350C', 'Response_y': '200C'}, axis=1)\n",
    "data4= data4.dropna()\n",
    "l4=[]\n",
    "for i in range(len(data4)):\n",
    "    l4.append('Formal_cycle')\n",
    "data4['class']=l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [data1, data2, data3,data4]\n",
    "data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the first column\n",
    "data = data.drop('Time(s)', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the sting values to float values\n",
    "for i in range(len(data['250C'])):\n",
    "    data['250C'].iloc[i]=float(data['250C'].iloc[i].replace(\",\", \".\"))\n",
    "    data['300C'].iloc[i]=float(data['300C'].iloc[i].replace(\",\", \".\"))\n",
    "    data['350C'].iloc[i]=float(data['350C'].iloc[i].replace(\",\", \".\"))\n",
    "    data['200C'].iloc[i]=float(data['200C'].iloc[i].replace(\",\", \".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE = LabelEncoder()\n",
    "data['Class'] = LE.fit_transform(data['class'])\n",
    "data = data.drop('class', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>250C</th>\n",
       "      <th>300C</th>\n",
       "      <th>350C</th>\n",
       "      <th>200C</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.37482</td>\n",
       "      <td>1.09649</td>\n",
       "      <td>1.27834</td>\n",
       "      <td>1.09493</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.07649</td>\n",
       "      <td>1.11883</td>\n",
       "      <td>1.18536</td>\n",
       "      <td>1.07331</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.71556</td>\n",
       "      <td>1.38251</td>\n",
       "      <td>0.97727</td>\n",
       "      <td>1.05975</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.2907</td>\n",
       "      <td>2.07406</td>\n",
       "      <td>0.96219</td>\n",
       "      <td>1.15781</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.44272</td>\n",
       "      <td>1.71841</td>\n",
       "      <td>1.06721</td>\n",
       "      <td>1.07972</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.0771</td>\n",
       "      <td>2.19188</td>\n",
       "      <td>0.80677</td>\n",
       "      <td>0.50304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.94464</td>\n",
       "      <td>1.89853</td>\n",
       "      <td>0.79466</td>\n",
       "      <td>-0.47545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.8505</td>\n",
       "      <td>2.463</td>\n",
       "      <td>0.82632</td>\n",
       "      <td>0.53851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.40065</td>\n",
       "      <td>2.68766</td>\n",
       "      <td>0.82537</td>\n",
       "      <td>-0.1093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2.12915</td>\n",
       "      <td>2.60953</td>\n",
       "      <td>0.88577</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3136 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        250C     300C     350C     200C  Class\n",
       "0    2.37482  1.09649  1.27834  1.09493      2\n",
       "1    2.07649  1.11883  1.18536  1.07331      2\n",
       "2    1.71556  1.38251  0.97727  1.05975      2\n",
       "3     2.2907  2.07406  0.96219  1.15781      2\n",
       "4    1.44272  1.71841  1.06721  1.07972      2\n",
       "..       ...      ...      ...      ...    ...\n",
       "995  -0.0771  2.19188  0.80677  0.50304      0\n",
       "996  0.94464  1.89853  0.79466 -0.47545      0\n",
       "997   1.8505    2.463  0.82632  0.53851      0\n",
       "998  0.40065  2.68766  0.82537  -0.1093      0\n",
       "999  2.12915  2.60953  0.88577   -0.285      0\n",
       "\n",
       "[3136 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Netwrok "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = ['Class']#select tha label\n",
    "predictors = list(set(list(data.columns))-set(target_column))#select the feature\n",
    "data[predictors] = data[predictors]/data[predictors].max()#normalize the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[predictors].values#get the values of the feature\n",
    "y = data[target_column].values#get tha value of the label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=40)#split tha data into 80% traing and 20%test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train)#categorise training label\n",
    "y_test = to_categorical(y_test)#categorise testing label\n",
    "count_classes = y_test.shape[1] #count the number of classes\n",
    "print(count_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model \n",
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(500, activation='tanh', input_dim=4))#create the first hidden layer with 500 layers \n",
    "model.add(Dropout(0.2))#using dorpout for underfitting \n",
    "model.add(Dense(600, activation='tanh'))#create the first hidden layer with 500 layers\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(800, activation='tanh'))#create the first hidden layer with 800 layers\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))#create the first hidden layer with 100 layers\n",
    "model.add(Dense(50, activation='relu'))#create the first hidden layer with 50 layers\n",
    "model.add(Dense(4, activation='softmax'))#create the first hidden layer with 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])#optimzing the model using adam and 'categorical_crossentropy' as loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2508/2508 [==============================] - 2s 711us/step - loss: 0.7888 - accuracy: 0.6866\n",
      "Epoch 2/20\n",
      "2508/2508 [==============================] - 1s 506us/step - loss: 0.6032 - accuracy: 0.7683\n",
      "Epoch 3/20\n",
      "2508/2508 [==============================] - 1s 446us/step - loss: 0.4893 - accuracy: 0.8110\n",
      "Epoch 4/20\n",
      "2508/2508 [==============================] - 1s 474us/step - loss: 0.4369 - accuracy: 0.8425\n",
      "Epoch 5/20\n",
      "2508/2508 [==============================] - 1s 523us/step - loss: 0.3511 - accuracy: 0.8780\n",
      "Epoch 6/20\n",
      "2508/2508 [==============================] - 1s 493us/step - loss: 0.4024 - accuracy: 0.8636\n",
      "Epoch 7/20\n",
      "2508/2508 [==============================] - 2s 716us/step - loss: 0.3936 - accuracy: 0.8541\n",
      "Epoch 8/20\n",
      "2508/2508 [==============================] - 2s 698us/step - loss: 0.3294 - accuracy: 0.8812\n",
      "Epoch 9/20\n",
      "2508/2508 [==============================] - 2s 645us/step - loss: 0.2911 - accuracy: 0.8939\n",
      "Epoch 10/20\n",
      "2508/2508 [==============================] - 2s 625us/step - loss: 0.2725 - accuracy: 0.9023\n",
      "Epoch 11/20\n",
      "2508/2508 [==============================] - 2s 719us/step - loss: 0.3026 - accuracy: 0.8935\n",
      "Epoch 12/20\n",
      "2508/2508 [==============================] - 2s 665us/step - loss: 0.2680 - accuracy: 0.9055\n",
      "Epoch 13/20\n",
      "2508/2508 [==============================] - 2s 647us/step - loss: 0.2639 - accuracy: 0.8995\n",
      "Epoch 14/20\n",
      "2508/2508 [==============================] - 2s 705us/step - loss: 0.2358 - accuracy: 0.9159\n",
      "Epoch 15/20\n",
      "2508/2508 [==============================] - 2s 696us/step - loss: 0.2659 - accuracy: 0.9011\n",
      "Epoch 16/20\n",
      "2508/2508 [==============================] - 2s 721us/step - loss: 0.2715 - accuracy: 0.9051\n",
      "Epoch 17/20\n",
      "2508/2508 [==============================] - 2s 639us/step - loss: 0.2393 - accuracy: 0.9115\n",
      "Epoch 18/20\n",
      "2508/2508 [==============================] - 2s 626us/step - loss: 0.2397 - accuracy: 0.9083\n",
      "Epoch 19/20\n",
      "2508/2508 [==============================] - 2s 719us/step - loss: 0.2285 - accuracy: 0.9139\n",
      "Epoch 20/20\n",
      "2508/2508 [==============================] - 2s 630us/step - loss: 0.2128 - accuracy: 0.9175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x188d52b6cc8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20) #fit the model with 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9461722373962402\n"
     ]
    }
   ],
   "source": [
    "pred_train= model.predict(X_train) #predict the model \n",
    "scores = model.evaluate(X_train, y_train, verbose=0) #compute the accuracy \n",
    "print('Accuracy : ',scores[1])   #display the accuracy \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
